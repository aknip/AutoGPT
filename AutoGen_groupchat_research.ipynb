{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Autogen-AutoGPT/blob/main/AutoGen_groupchat_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya58uBwYULFn"
      },
      "source": [
        "# Auto Generated Agent Chat: Performs Research with Multi-Agent Group Chat\n",
        "\n",
        "\n",
        "Notes:\n",
        "- Problems with nr. of tokens/min\n",
        "- Source: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb\n",
        "\n",
        "\n",
        "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
        "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "id": "j6htRpKUUX_9",
        "outputId": "2bfce512-5437-4e0a-dd0f-b6fa464f3e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Secrets (JSON string): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_x03YR3ULFo"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install pyautogen~=0.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6EaZY0nULFp"
      },
      "source": [
        "## Set your API Endpoint\n",
        "\n",
        "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4F4sSQ9ULFp"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "\n",
        "config_list_gpt4 = [{'model': 'gpt-4', 'api_key': CREDS['OpenAI']['v1']['credential']}]\n",
        "\n",
        "#print(config_list_gpt4)\n",
        "\n",
        "llm_config = {\n",
        "    \"seed\": 43,  # change the seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": config_list_gpt4,\n",
        "    \"request_timeout\": 120,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCabmJbGULFp"
      },
      "source": [
        "## Construct Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df5-tcMlULFp"
      },
      "outputs": [],
      "source": [
        "gpt4_config = {\n",
        "    \"seed\": 42,  # change the seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": config_list_gpt4,\n",
        "    \"request_timeout\": 120,\n",
        "}\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "   name=\"Admin\",\n",
        "   system_message=\"A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
        "   code_execution_config=False,\n",
        ")\n",
        "engineer = autogen.AssistantAgent(\n",
        "    name=\"Engineer\",\n",
        "    llm_config=gpt4_config,\n",
        "    system_message='''Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
        "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
        "''',\n",
        ")\n",
        "scientist = autogen.AssistantAgent(\n",
        "    name=\"Scientist\",\n",
        "    llm_config=gpt4_config,\n",
        "    system_message=\"\"\"Scientist. You follow an approved plan. You are able to categorize papers after seeing their abstracts printed. You don't write code.\"\"\"\n",
        ")\n",
        "planner = autogen.AssistantAgent(\n",
        "    name=\"Planner\",\n",
        "    system_message='''Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin approval.\n",
        "The plan may involve an engineer who can write code and a scientist who doesn't write code.\n",
        "Explain the plan first. Be clear which step is performed by an engineer, and which step is performed by a scientist.\n",
        "''',\n",
        "    llm_config=gpt4_config,\n",
        ")\n",
        "executor = autogen.UserProxyAgent(\n",
        "    name=\"Executor\",\n",
        "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"paper\"},\n",
        ")\n",
        "critic = autogen.AssistantAgent(\n",
        "    name=\"Critic\",\n",
        "    system_message=\"Critic. Double check plan, claims, code from other agents and provide feedback. Check whether the plan includes adding verifiable info such as source URL.\",\n",
        "    llm_config=gpt4_config,\n",
        ")\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, engineer, scientist, planner, executor, critic], messages=[], max_round=50)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZ-b-_YULFq"
      },
      "source": [
        "## Start Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mha0ekPOULFq",
        "outputId": "1adfd64c-f69b-4d86-8369-07c8dff1bc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Admin (to chat_manager):\n",
            "\n",
            "\n",
            "find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Planner (to chat_manager):\n",
            "\n",
            "Plan:\n",
            "\n",
            "1. Engineer: Write a script to scrape arXiv for papers on LLM (Language Model) applications published in the last week. The script should extract the title, authors, abstract, and link to the paper.\n",
            "\n",
            "2. Scientist: Review the scraped data to identify the different domains in which LLM is applied. This could be based on the content of the abstracts or the sections of arXiv where the papers are published.\n",
            "\n",
            "3. Engineer: Modify the script to categorize the papers based on the domains identified by the scientist. The script should output a markdown table with columns for the domain, title, authors, abstract, and link.\n",
            "\n",
            "4. Scientist: Review the markdown table to ensure the papers are correctly categorized and the information is accurate.\n",
            "\n",
            "5. Engineer: Make any necessary revisions to the script based on the scientist's feedback.\n",
            "\n",
            "6. Scientist: Give final approval of the markdown table.\n",
            "\n",
            "7. Engineer: Submit the final markdown table.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Critic (to chat_manager):\n",
            "\n",
            "The plan is well-structured and clear. However, it lacks a step for verifying the information. It's important to ensure that the information scraped from arXiv is accurate and reliable. Here's a revised plan:\n",
            "\n",
            "1. Engineer: Write a script to scrape arXiv for papers on LLM (Language Model) applications published in the last week. The script should extract the title, authors, abstract, and link to the paper.\n",
            "\n",
            "2. Scientist: Review the scraped data to identify the different domains in which LLM is applied. This could be based on the content of the abstracts or the sections of arXiv where the papers are published.\n",
            "\n",
            "3. Engineer: Modify the script to categorize the papers based on the domains identified by the scientist. The script should output a markdown table with columns for the domain, title, authors, abstract, and link.\n",
            "\n",
            "4. Scientist: Review the markdown table to ensure the papers are correctly categorized and the information is accurate.\n",
            "\n",
            "5. Scientist: Verify the information in the table by cross-checking a sample of the papers with their entries on arXiv. \n",
            "\n",
            "6. Engineer: Make any necessary revisions to the script based on the scientist's feedback.\n",
            "\n",
            "7. Scientist: Give final approval of the markdown table after verification.\n",
            "\n",
            "8. Engineer: Submit the final markdown table. \n",
            "\n",
            "This plan ensures that the information in the table is accurate and verifiable.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: ok\n",
            "Admin (to chat_manager):\n",
            "\n",
            "ok\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Engineer (to chat_manager):\n",
            "\n",
            "To accomplish this task, we will use the `arxiv` Python library, which is a wrapper for the arXiv API. This library allows us to search for and retrieve metadata for arXiv papers.\n",
            "\n",
            "First, we need to install the `arxiv` library. You can do this by running the following command:\n",
            "\n",
            "```python\n",
            "!pip install arxiv\n",
            "```\n",
            "\n",
            "Next, we will write a script to search for papers on LLM applications that were published in the last week. We will then categorize these papers by domain and create a markdown table with this information.\n",
            "\n",
            "Here is the Python script:\n",
            "\n",
            "```python\n",
            "import arxiv\n",
            "import datetime\n",
            "import pandas as pd\n",
            "\n",
            "# Define the date one week ago\n",
            "one_week_ago = (datetime.datetime.now() - datetime.timedelta(days=7)).strftime('%Y%m%d%H%M%S')\n",
            "\n",
            "# Search for papers on LLM applications\n",
            "search = arxiv.Search(\n",
            "  query=\"LLM applications\",\n",
            "  max_results=100,\n",
            "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
            "  sort_order=arxiv.SortOrder.Descending\n",
            ")\n",
            "\n",
            "# Initialize a list to store the paper data\n",
            "papers = []\n",
            "\n",
            "# Loop through the results\n",
            "for result in search.get():\n",
            "  # Check if the paper was published in the last week\n",
            "  if result.published.strftime('%Y%m%d%H%M%S') >= one_week_ago:\n",
            "    # Extract the domain from the categories\n",
            "    domain = result.categories[0].split('.')[0]\n",
            "    # Add the paper data to the list\n",
            "    papers.append([domain, result.title, ', '.join(result.authors), result.summary, result.entry_id])\n",
            "\n",
            "# Create a DataFrame from the paper data\n",
            "df = pd.DataFrame(papers, columns=['Domain', 'Title', 'Authors', 'Abstract', 'Link'])\n",
            "\n",
            "# Convert the DataFrame to a markdown table\n",
            "markdown_table = df.to_markdown(index=False)\n",
            "\n",
            "# Print the markdown table\n",
            "print(markdown_table)\n",
            "```\n",
            "\n",
            "This script first defines the date one week ago. It then searches for papers on LLM applications and loops through the results. For each result, it checks if the paper was published in the last week. If it was, it extracts the domain from the categories, adds the paper data to a list, and then creates a DataFrame from this list. Finally, it converts the DataFrame to a markdown table and prints it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.code_utils:execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executor (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "  File \"\", line 1\n",
            "    !pip install arxiv\n",
            "    ^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Engineer (to chat_manager):\n",
            "\n",
            "I apologize for the confusion. The `!pip install arxiv` command is intended to be run in a Jupyter notebook. If you're not using a Jupyter notebook, you can install the `arxiv` library by running `pip install arxiv` in your command line.\n",
            "\n",
            "Let's proceed with the Python script to fetch the papers. Please ensure that the `arxiv` library is installed before running the script.\n",
            "\n",
            "```python\n",
            "import arxiv\n",
            "import datetime\n",
            "import pandas as pd\n",
            "\n",
            "# Define the date one week ago\n",
            "one_week_ago = (datetime.datetime.now() - datetime.timedelta(days=7)).strftime('%Y%m%d%H%M%S')\n",
            "\n",
            "# Search for papers on LLM applications\n",
            "search = arxiv.Search(\n",
            "  query=\"LLM applications\",\n",
            "  max_results=100,\n",
            "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
            "  sort_order=arxiv.SortOrder.Descending\n",
            ")\n",
            "\n",
            "# Initialize a list to store the paper data\n",
            "papers = []\n",
            "\n",
            "# Loop through the results\n",
            "for result in search.get():\n",
            "  # Check if the paper was published in the last week\n",
            "  if result.published.strftime('%Y%m%d%H%M%S') >= one_week_ago:\n",
            "    # Extract the domain from the categories\n",
            "    domain = result.categories[0].split('.')[0]\n",
            "    # Add the paper data to the list\n",
            "    papers.append([domain, result.title, ', '.join(result.authors), result.summary, result.entry_id])\n",
            "\n",
            "# Create a DataFrame from the paper data\n",
            "df = pd.DataFrame(papers, columns=['Domain', 'Title', 'Authors', 'Abstract', 'Link'])\n",
            "\n",
            "# Convert the DataFrame to a markdown table\n",
            "markdown_table = df.to_markdown(index=False)\n",
            "\n",
            "# Print the markdown table\n",
            "print(markdown_table)\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.code_utils:execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executor (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 1, in <module>\n",
            "    import arxiv\n",
            "ModuleNotFoundError: No module named 'arxiv'\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Engineer (to chat_manager):\n",
            "\n",
            "I apologize for the confusion. It seems that the environment where the code is being executed does not have the `arxiv` library installed, and we are unable to install it directly here.\n",
            "\n",
            "In this case, we can use an alternative approach by using the `requests` and `feedparser` libraries to fetch and parse the RSS feed from arXiv. These libraries are commonly included in Python environments.\n",
            "\n",
            "Here is the Python script:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "import feedparser\n",
            "import pandas as pd\n",
            "from datetime import datetime, timedelta\n",
            "\n",
            "# Define the date one week ago\n",
            "one_week_ago = (datetime.now() - timedelta(days=7)).date()\n",
            "\n",
            "# URL for the arXiv API\n",
            "url = \"http://export.arxiv.org/api/query?\"\n",
            "\n",
            "# Parameters for the query\n",
            "params = {\n",
            "    \"search_query\": \"all:LLM applications\",\n",
            "    \"start\": 0,\n",
            "    \"max_results\": 100,\n",
            "    \"sortBy\": \"submittedDate\",\n",
            "    \"sortOrder\": \"descending\"\n",
            "}\n",
            "\n",
            "# Send a GET request to the arXiv API\n",
            "response = requests.get(url, params=params)\n",
            "\n",
            "# Parse the response\n",
            "feed = feedparser.parse(response.content)\n",
            "\n",
            "# Initialize a list to store the paper data\n",
            "papers = []\n",
            "\n",
            "# Loop through the entries in the feed\n",
            "for entry in feed.entries:\n",
            "    # Parse the published date\n",
            "    published_date = datetime.strptime(entry.published, '%Y-%m-%dT%H:%M:%SZ').date()\n",
            "\n",
            "    # Check if the paper was published in the last week\n",
            "    if published_date >= one_week_ago:\n",
            "        # Extract the domain from the categories\n",
            "        domain = entry.arxiv_primary_category['term'].split('.')[0]\n",
            "\n",
            "        # Add the paper data to the list\n",
            "        papers.append([domain, entry.title, entry.author, entry.summary, entry.link])\n",
            "\n",
            "# Create a DataFrame from the paper data\n",
            "df = pd.DataFrame(papers, columns=['Domain', 'Title', 'Authors', 'Abstract', 'Link'])\n",
            "\n",
            "# Convert the DataFrame to a markdown table\n",
            "markdown_table = df.to_markdown(index=False)\n",
            "\n",
            "# Print the markdown table\n",
            "print(markdown_table)\n",
            "```\n",
            "\n",
            "This script sends a GET request to the arXiv API with a query for \"LLM applications\". It then parses the response and loops through the entries in the feed. For each entry, it checks if the paper was published in the last week. If it was, it extracts the domain from the categories, adds the paper data to a list, and then creates a DataFrame from this list. Finally, it converts the DataFrame to a markdown table and prints it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.code_utils:execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executor (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 2, in <module>\n",
            "    import feedparser\n",
            "ModuleNotFoundError: No module named 'feedparser'\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Engineer (to chat_manager):\n",
            "\n",
            "I apologize for the confusion. It seems that the environment where the code is being executed does not have the `feedparser` library installed, and we are unable to install it directly here.\n",
            "\n",
            "In this case, we can use an alternative approach by using the `requests` and `bs4` (BeautifulSoup) libraries to fetch and parse the HTML page from arXiv. These libraries are commonly included in Python environments.\n",
            "\n",
            "Here is the Python script:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "import pandas as pd\n",
            "from datetime import datetime, timedelta\n",
            "\n",
            "# Define the date one week ago\n",
            "one_week_ago = (datetime.now() - timedelta(days=7)).date()\n",
            "\n",
            "# URL for the arXiv search page\n",
            "url = \"https://arxiv.org/search/?query=LLM+applications&searchtype=all&abstracts=show&order=-announced_date_first&size=50\"\n",
            "\n",
            "# Send a GET request to the arXiv search page\n",
            "response = requests.get(url)\n",
            "\n",
            "# Parse the response\n",
            "soup = BeautifulSoup(response.content, 'html.parser')\n",
            "\n",
            "# Initialize a list to store the paper data\n",
            "papers = []\n",
            "\n",
            "# Loop through the entries in the page\n",
            "for entry in soup.find_all('li', class_='arxiv-result'):\n",
            "    # Parse the published date\n",
            "    published_date = datetime.strptime(entry.find('p', class_='is-size-7').text.split(';')[1].strip(), '%a, %d %b %Y %H:%M:%S GMT').date()\n",
            "\n",
            "    # Check if the paper was published in the last week\n",
            "    if published_date >= one_week_ago:\n",
            "        # Extract the domain from the categories\n",
            "        domain = entry.find('div', class_='tags is-inline-block').text.split()[0]\n",
            "\n",
            "        # Add the paper data to the list\n",
            "        papers.append([domain, entry.find('p', class_='title is-5 mathjax').text.strip(), entry.find('p', class_='authors').text.strip(), entry.find('span', class_='abstract-full has-text-grey-dark mathjax').text.strip(), 'https://arxiv.org' + entry.find('p', class_='list-title is-inline-block').find('a')['href']])\n",
            "\n",
            "# Create a DataFrame from the paper data\n",
            "df = pd.DataFrame(papers, columns=['Domain', 'Title', 'Authors', 'Abstract', 'Link'])\n",
            "\n",
            "# Convert the DataFrame to a markdown table\n",
            "markdown_table = df.to_markdown(index=False)\n",
            "\n",
            "# Print the markdown table\n",
            "print(markdown_table)\n",
            "```\n",
            "\n",
            "This script sends a GET request to the arXiv search page with a query for \"LLM applications\". It then parses the response and loops through the entries in the page. For each entry, it checks if the paper was published in the last week. If it was, it extracts the domain from the categories, adds the paper data to a list, and then creates a DataFrame from this list. Finally, it converts the DataFrame to a markdown table and prints it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.code_utils:execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executor (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 24, in <module>\n",
            "    published_date = datetime.strptime(entry.find('p', class_='is-size-7').text.split(';')[1].strip(), '%a, %d %b %Y %H:%M:%S GMT').date()\n",
            "  File \"/usr/lib/python3.10/_strptime.py\", line 568, in _strptime_datetime\n",
            "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
            "  File \"/usr/lib/python3.10/_strptime.py\", line 349, in _strptime\n",
            "    raise ValueError(\"time data %r does not match format %r\" %\n",
            "ValueError: time data 'originally announced October 2023.' does not match format '%a, %d %b %Y %H:%M:%S GMT'\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Engineer (to chat_manager):\n",
            "\n",
            "I apologize for the confusion. It seems that the date format or the date string extracted from the webpage is not as expected, causing the `strptime` function to raise a `ValueError`.\n",
            "\n",
            "In this case, we can use an alternative approach by using the `requests` and `lxml` libraries to fetch and parse the HTML page from arXiv. These libraries are commonly included in Python environments.\n",
            "\n",
            "Here is the Python script:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "from lxml import html\n",
            "import pandas as pd\n",
            "from datetime import datetime, timedelta\n",
            "\n",
            "# Define the date one week ago\n",
            "one_week_ago = (datetime.now() - timedelta(days=7)).date()\n",
            "\n",
            "# URL for the arXiv search page\n",
            "url = \"https://arxiv.org/search/?query=LLM+applications&searchtype=all&abstracts=show&order=-announced_date_first&size=50\"\n",
            "\n",
            "# Send a GET request to the arXiv search page\n",
            "response = requests.get(url)\n",
            "\n",
            "# Parse the response\n",
            "tree = html.fromstring(response.content)\n",
            "\n",
            "# Initialize a list to store the paper data\n",
            "papers = []\n",
            "\n",
            "# Loop through the entries in the page\n",
            "for entry in tree.xpath('//li[contains(@class, \"arxiv-result\")]'):\n",
            "    # Parse the published date\n",
            "    published_date = datetime.strptime(entry.xpath('.//p[contains(@class, \"is-size-7\")]/text()')[0].split(';')[1].strip(), '%a, %d %b %Y %H:%M:%S GMT').date()\n",
            "\n",
            "    # Check if the paper was published in the last week\n",
            "    if published_date >= one_week_ago:\n",
            "        # Extract the domain from the categories\n",
            "        domain = entry.xpath('.//div[contains(@class, \"tags is-inline-block\")]/text()')[0].split()[0]\n",
            "\n",
            "        # Add the paper data to the list\n",
            "        papers.append([domain, entry.xpath('.//p[contains(@class, \"title is-5 mathjax\")]/text()')[0].strip(), entry.xpath('.//p[contains(@class, \"authors\")]/text()')[0].strip(), entry.xpath('.//span[contains(@class, \"abstract-full has-text-grey-dark mathjax\")]/text()')[0].strip(), 'https://arxiv.org' + entry.xpath('.//p[contains(@class, \"list-title is-inline-block\")]/a/@href')[0]])\n",
            "\n",
            "# Create a DataFrame from the paper data\n",
            "df = pd.DataFrame(papers, columns=['Domain', 'Title', 'Authors', 'Abstract', 'Link'])\n",
            "\n",
            "# Convert the DataFrame to a markdown table\n",
            "markdown_table = df.to_markdown(index=False)\n",
            "\n",
            "# Print the markdown table\n",
            "print(markdown_table)\n",
            "```\n",
            "\n",
            "This script sends a GET request to the arXiv search page with a query for \"LLM applications\". It then parses the response and loops through the entries in the page. For each entry, it checks if the paper was published in the last week. If it was, it extracts the domain from the categories, adds the paper data to a list, and then creates a DataFrame from this list. Finally, it converts the DataFrame to a markdown table and prints it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.code_utils:execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executor (to chat_manager):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "Traceback (most recent call last):\n",
            "  File \"\", line 24, in <module>\n",
            "    published_date = datetime.strptime(entry.xpath('.//p[contains(@class, \"is-size-7\")]/text()')[0].split(';')[1].strip(), '%a, %d %b %Y %H:%M:%S GMT').date()\n",
            "  File \"/usr/lib/python3.10/_strptime.py\", line 568, in _strptime_datetime\n",
            "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
            "  File \"/usr/lib/python3.10/_strptime.py\", line 349, in _strptime\n",
            "    raise ValueError(\"time data %r does not match format %r\" %\n",
            "ValueError: time data '' does not match format '%a, %d %b %Y %H:%M:%S GMT'\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.completion: 10-25 05:39:45] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-LpwTUpjMES9WgS6UeGXXfs47 on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-LpwTUpjMES9WgS6UeGXXfs47 on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.completion: 10-25 05:39:55] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-LpwTUpjMES9WgS6UeGXXfs47 on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-4 in organization org-LpwTUpjMES9WgS6UeGXXfs47 on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a34f81f19c57>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m user_proxy.initiate_chat(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     message=\"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0mfind\u001b[0m \u001b[0mpapers\u001b[0m \u001b[0mon\u001b[0m \u001b[0mLLM\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marxiv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmarkdown\u001b[0m \u001b[0mtable\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\",\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36minitiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \"\"\"\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_init_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     async def a_initiate_chat(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_oai_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mrecipient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_reply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mreceive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrequest_reply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreply_at_receive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mgenerate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    779\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trigger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m                 \u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreply_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/groupchat.py\u001b[0m in \u001b[0;36mrun_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;31m# admin agent is one of the participants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mspeaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroupchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmin_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;31m# admin agent is not found in the participants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mgenerate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    779\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trigger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m                 \u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreply_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreply_func_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mcheck_termination_and_human_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mno_human_input_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuman_input_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ALWAYS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             reply = self.get_human_input(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0;34mf\"Provide feedback to {sender.name}. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36mget_human_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhuman\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \"\"\"\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=\"\"\"\n",
        "find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.\n",
        "\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj0ztK_8ULFq"
      },
      "source": [
        "## Create Group Chat without Critic for Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4c1eXFSULFr",
        "outputId": "c12d4941-bcee-40eb-db15-bb2e90835a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
            "\n",
            "\n",
            "find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
            "\n",
            "Plan:\n",
            "\n",
            "1. Engineer: Write a script to scrape the arXiv website for papers related to LLM (Language Model) applications published in the last week. The script should extract the title, authors, abstract, and link to the paper.\n",
            "\n",
            "2. Scientist: Review the scraped data to identify the different domains in which LLM is applied. This could be based on keywords in the title or abstract, or the scientist's knowledge of the field.\n",
            "\n",
            "3. Engineer: Modify the script to categorize the papers based on the domains identified by the scientist. The script should output a markdown table with columns for the domain, title, authors, abstract, and link.\n",
            "\n",
            "4. Scientist: Review the markdown table to ensure the papers are correctly categorized and the information is accurate.\n",
            "\n",
            "5. Engineer: Make any necessary revisions to the script based on the scientist's feedback.\n",
            "\n",
            "6. Scientist: Give final approval of the markdown table.\n",
            "\n",
            "7. Engineer: Submit the final markdown table.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "groupchat_nocritic = autogen.GroupChat(agents=[user_proxy, engineer, scientist, planner, executor], messages=[], max_round=50)\n",
        "for agent in groupchat.agents:\n",
        "    agent.reset()\n",
        "manager_nocritic = autogen.GroupChatManager(groupchat=groupchat_nocritic, llm_config=gpt4_config)\n",
        "user_proxy.initiate_chat(\n",
        "    manager_nocritic,\n",
        "    message=\"\"\"\n",
        "find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.\n",
        "\"\"\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "flaml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}